# ğŸ§  AI Docstring Generator (with Ollama)

A simple VS Code extension that uses an open-source LLM (via [Ollama](https://ollama.com)) to generate brief and clear `Python` or `Java` docstrings for your functions.

## âœ¨ Features

- Input any Python or Java function ( and/or Classes ) and receive an autogenerated docstring.
- Uses `deepseek-coder` (or other Ollama-compatible models) locallyâ€”no internet or API key required.

## ğŸš€ Getting Started

### 1. Install Ollama

Install and run Ollama from [Ollama](https://ollama.com), then pull a model:

```bash
ollama pull deepseek-r1:latest 
```
> This will download the model `deepseek-r1:7b` Model.
this is what I used for the project 

> You can choose anything you want but do remember to change the same in the `extension.ts`.

> Choose from here [Models](https://ollama.com/search)


### 2. Clone & Install Extension

```zsh
git clone https://github.com/SSK0414/ai-docstring2
cd ai-docstring-generator
npm install
```

### 3. Run in VS Code

Press `F5` in VS Code to launch the extension in a new window.

You can use the extension following the steps:
  1) highlight a function 
  2) Use the command palette (`Cmd+Shift+P` or `Ctrl+Shift+P`) and search: `docstring`
     (or)
     Use the hot key `Ctrl+Shift+H` to run the extension.
  3) Wait.
  > This will depend on the computational power of your system

  > It takes `20-25 seconds` for me and I use a M1 Macbook
 
## ğŸ§ª Testing

To run tests:

```bash
npm test
```

Tests ensure command registration, activation, and message flow.

## ğŸ“ File Structure

```
src/
â”œâ”€â”€ extension.ts         # Main extension code
â””â”€â”€ test/suite/          # Mocha tests
```

## ğŸ›  Tech Stack

- TypeScript
- Ollama (LLM runtime)

